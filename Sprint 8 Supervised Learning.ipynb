{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border:solid blue 2px; padding: 20px\"> \n",
    "\n",
    "<strong>Reviewer's Introduction</strong>\n",
    "\n",
    "Hello Collin! üëã \n",
    "\n",
    "I'm happy to review your project today.\n",
    "\n",
    "I will categorize my comments in green, blue or red boxes like this:\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Success:</b> Everything is done successfully.\n",
    "</div>\n",
    "<div class=\"alert alert-warning\">\n",
    "    <b>Remarks:</b> Suggestions for optimizations or improvements.\n",
    "</div>\n",
    "<div class=\"alert alert-danger\">\n",
    "    <b>Needs fixing:</b> This must be fixed for a project to be approved.\n",
    "</div>\n",
    "\n",
    "Please don't remove my comments :) If you have any questions or comments, don't hesitate to respond to my comments by creating a box that looks like this: \n",
    "<div class=\"alert alert-info\"> <b>Student's comment:</b> Your text here.</div>    \n",
    "<br>\n",
    "\n",
    "\n",
    "üìå Here's how to create code for student comments inside a Markdown cell:\n",
    "    \n",
    "    \n",
    "    <div class=\"alert alert-info\">\n",
    "    <b> Student's comment</b>\n",
    "\n",
    "    Your text here. \n",
    "    </div>\n",
    "\n",
    "You can find out how to **format text** in a Markdown cell or how to **add links** [here](https://sqlbak.com/blog/jupyter-notebook-markdown-cheatsheet). \n",
    "\n",
    "\n",
    "<hr>\n",
    "Reviewer: Han Lee (hanlee_97297 on Discord)<br>\n",
    "Don‚Äôt forget to rate your experience by leaving feedback here:  \n",
    "<a href=\"https://form.typeform.com/to/msiTC4LB\" target=\"_blank\">https://form.typeform.com/to/msiTC4LB</a>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: solid blue 2px; padding: 15px; margin: 10px\">\n",
    "\t<b>Reviewer's Comments ‚Äì Iteration 1</b>\n",
    "\t\n",
    "Thank you for submitting this project. It is clear that you have a strong understanding of the material covered up to this point, from data exploration and cleaning, to machine learning fundamentals.\n",
    "\n",
    "<b>Notable strengths:</b>  \n",
    "\n",
    "‚úîÔ∏è Extensive and largely persuasive discussions interspersed throughout the project, including a strong conclusion. They really help your audience understand your thought process and decisions.\n",
    "\n",
    "‚úîÔ∏è A solid understanding of data imbalance, and how to address it via sampling.\n",
    "\n",
    "‚úîÔ∏è Translating data findings into actionable insights to meet business needs.\n",
    "\n",
    "\n",
    "<hr>\n",
    "\n",
    "A few things require your attention before approval. Please see my notes below for further info:\n",
    "\n",
    "üî¥ Please reconsider data imputation over dropping rows with null values in the `Tenure` column. \n",
    "\n",
    "üî¥ The data should be split into training, validation, and testing sets.\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"border: solid blue 2px; padding: 15px; margin: 10px\">\n",
    "\t<b>Reviewer's Comments ‚Äì Iteration 2</b>\n",
    "\n",
    "Congratulations! \n",
    "\n",
    "This project now meets all requirements ‚úÖ, and is approved. üéâ\n",
    "\n",
    "Great job addressing the requested changes from the first iteration!\n",
    "\n",
    "Please see my notes before for further discussion points.\n",
    "\n",
    "Again, well done, and I wish you continued success in the upcoming sprints.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
      "0          1    15634602  Hargrave          619    France  Female   42   \n",
      "1          2    15647311      Hill          608     Spain  Female   41   \n",
      "2          3    15619304      Onio          502    France  Female   42   \n",
      "3          4    15701354      Boni          699    France  Female   39   \n",
      "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
      "\n",
      "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
      "0     2.0       0.00              1          1               1   \n",
      "1     1.0   83807.86              1          0               1   \n",
      "2     8.0  159660.80              3          1               0   \n",
      "3     1.0       0.00              2          0               0   \n",
      "4     2.0  125510.82              1          1               1   \n",
      "\n",
      "   EstimatedSalary  Exited  \n",
      "0        101348.88       1  \n",
      "1        112542.58       0  \n",
      "2        113931.57       1  \n",
      "3         93826.63       0  \n",
      "4         79084.10       0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/datasets/Churn.csv')\n",
    "print(data.head())\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_necessary = data.drop(columns=['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "data_ohe = pd.get_dummies(data_necessary, drop_first=True)\n",
    "data_ohe['Tenure'] = data_ohe['Tenure'].fillna(data_ohe['Tenure'].median())\n",
    "target = data_ohe['Exited']\n",
    "features = data_ohe.drop('Exited', axis=1)\n",
    "features_train_val, features_test, target_train_val, target_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42\n",
    ")\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_train_val, target_train_val, test_size=0.25, random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Geography_Germany</th>\n",
       "      <th>Geography_Spain</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
       "0          619   42     2.0       0.00              1          1   \n",
       "1          608   41     1.0   83807.86              1          0   \n",
       "2          502   42     8.0  159660.80              3          1   \n",
       "3          699   39     1.0       0.00              2          0   \n",
       "4          850   43     2.0  125510.82              1          1   \n",
       "\n",
       "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
       "0               1        101348.88       1                  0   \n",
       "1               1        112542.58       0                  0   \n",
       "2               0        113931.57       1                  0   \n",
       "3               0         93826.63       0                  0   \n",
       "4               1         79084.10       0                  0   \n",
       "\n",
       "   Geography_Spain  Gender_Male  \n",
       "0                0            0  \n",
       "1                1            0  \n",
       "2                0            0  \n",
       "3                0            0  \n",
       "4                1            0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_ohe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <b>Reviewer's comment ‚Äì Iteration 1:</b><br>\n",
    "I agree with the decision to drop the unnecessary columns.\n",
    "\n",
    "Here are two requested changes:\n",
    "\n",
    "1. Dropping rows with null values in the `Tenure` column is a bit more nuanced, as such rows comprise roughly 10% of the dataset. By dropping these rows, you risk losing valuable data from the other features, while imputing it can distort this column. In this case, I believe it makes sense to impute it with the column's median value, and suggest that you give it a try. It would be interesting to discover whether it makes a difference in model performances.\n",
    "\n",
    "2. Please split the dataset into training, validation, and testing sets. Below, you both tune your hyperparameters and perform final testing on the same validation set. This can cause data leakage and lead to overfitting. The testing set should be untouched during training and tuning.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Fixed :) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <b>Reviewer's comment ‚Äì Iteration 2:</b><br>\n",
    "Well done!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CreditScore  Age  Tenure    Balance  NumOfProducts  HasCrCard  \\\n",
      "0          619   42     2.0       0.00              1          1   \n",
      "1          608   41     1.0   83807.86              1          0   \n",
      "2          502   42     8.0  159660.80              3          1   \n",
      "3          699   39     1.0       0.00              2          0   \n",
      "4          850   43     2.0  125510.82              1          1   \n",
      "\n",
      "   IsActiveMember  EstimatedSalary  Exited  Geography_Germany  \\\n",
      "0               1        101348.88       1                  0   \n",
      "1               1        112542.58       0                  0   \n",
      "2               0        113931.57       1                  0   \n",
      "3               0         93826.63       0                  0   \n",
      "4               1         79084.10       0                  0   \n",
      "\n",
      "   Geography_Spain  Gender_Male  \n",
      "0                0            0  \n",
      "1                1            0  \n",
      "2                0            0  \n",
      "3                0            0  \n",
      "4                1            0  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 12 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   CreditScore        10000 non-null  int64  \n",
      " 1   Age                10000 non-null  int64  \n",
      " 2   Tenure             10000 non-null  float64\n",
      " 3   Balance            10000 non-null  float64\n",
      " 4   NumOfProducts      10000 non-null  int64  \n",
      " 5   HasCrCard          10000 non-null  int64  \n",
      " 6   IsActiveMember     10000 non-null  int64  \n",
      " 7   EstimatedSalary    10000 non-null  float64\n",
      " 8   Exited             10000 non-null  int64  \n",
      " 9   Geography_Germany  10000 non-null  uint8  \n",
      " 10  Geography_Spain    10000 non-null  uint8  \n",
      " 11  Gender_Male        10000 non-null  uint8  \n",
      "dtypes: float64(3), int64(6), uint8(3)\n",
      "memory usage: 732.5 KB\n",
      "None\n",
      "(10000, 12)\n"
     ]
    }
   ],
   "source": [
    "print(data_ohe.head())\n",
    "print(data_ohe.info())\n",
    "print(data_ohe.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Preparation Strategy**\n",
    "\n",
    "- Firstly, I dropped any columns that don't influence one's decision to leave the bank (customer ID, surname, and the Row number columns).\n",
    "- Secondly, I created dummy columns for the geography and gender columns since those were categorical columns that are best used when numeric values are assigned in place of categorical ones.\n",
    "- Thirdly, I filled any rows with missing values in the \"Tenure\" with the median.\n",
    "- Lastly, I split the data into a training, validation, and test set at a ratio of 60-20-20 respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column: CreditScore\n",
      "850    233\n",
      "678     63\n",
      "655     54\n",
      "667     53\n",
      "705     53\n",
      "      ... \n",
      "412      1\n",
      "351      1\n",
      "365      1\n",
      "373      1\n",
      "423      1\n",
      "Name: CreditScore, Length: 460, dtype: int64\n",
      "\n",
      "Column: Age\n",
      "37    478\n",
      "38    477\n",
      "35    474\n",
      "36    456\n",
      "34    447\n",
      "     ... \n",
      "92      2\n",
      "88      1\n",
      "82      1\n",
      "85      1\n",
      "83      1\n",
      "Name: Age, Length: 70, dtype: int64\n",
      "\n",
      "Column: Tenure\n",
      "5.0     1836\n",
      "1.0      952\n",
      "2.0      950\n",
      "8.0      933\n",
      "3.0      928\n",
      "7.0      925\n",
      "4.0      885\n",
      "9.0      882\n",
      "6.0      881\n",
      "10.0     446\n",
      "0.0      382\n",
      "Name: Tenure, dtype: int64\n",
      "\n",
      "Column: Balance\n",
      "0.00         3617\n",
      "105473.74       2\n",
      "130170.82       2\n",
      "72594.00        1\n",
      "139723.90       1\n",
      "             ... \n",
      "130306.49       1\n",
      "92895.56        1\n",
      "132005.77       1\n",
      "166287.85       1\n",
      "104001.38       1\n",
      "Name: Balance, Length: 6382, dtype: int64\n",
      "\n",
      "Column: NumOfProducts\n",
      "1    5084\n",
      "2    4590\n",
      "3     266\n",
      "4      60\n",
      "Name: NumOfProducts, dtype: int64\n",
      "\n",
      "Column: HasCrCard\n",
      "1    7055\n",
      "0    2945\n",
      "Name: HasCrCard, dtype: int64\n",
      "\n",
      "Column: IsActiveMember\n",
      "1    5151\n",
      "0    4849\n",
      "Name: IsActiveMember, dtype: int64\n",
      "\n",
      "Column: EstimatedSalary\n",
      "24924.92     2\n",
      "109145.20    1\n",
      "59755.14     1\n",
      "1557.82      1\n",
      "117202.19    1\n",
      "            ..\n",
      "37674.47     1\n",
      "158043.11    1\n",
      "103792.53    1\n",
      "182266.01    1\n",
      "155061.97    1\n",
      "Name: EstimatedSalary, Length: 9999, dtype: int64\n",
      "\n",
      "Column: Exited\n",
      "0    7963\n",
      "1    2037\n",
      "Name: Exited, dtype: int64\n",
      "\n",
      "Column: Geography_Germany\n",
      "0    7491\n",
      "1    2509\n",
      "Name: Geography_Germany, dtype: int64\n",
      "\n",
      "Column: Geography_Spain\n",
      "0    7523\n",
      "1    2477\n",
      "Name: Geography_Spain, dtype: int64\n",
      "\n",
      "Column: Gender_Male\n",
      "1    5457\n",
      "0    4543\n",
      "Name: Gender_Male, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for col in data_ohe.columns:\n",
    "    print(f\"\\nColumn: {col}\")\n",
    "    print(data_ohe[col].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Imbalance Examination**\n",
    "\n",
    "- Looking at the target column (Exited), most customers stay with the bank, and only about 20% have chosen to leave. This number is still extremely significant to a bank with tens of thousands of customers and a matter of millions (maybe even billions) of dollars.\n",
    "- In regards to the significance for a machine learning model, this is a huge imbalance and needs to be handled before a model's accuracy can be taken seriously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best # of estimators: 38\n"
     ]
    }
   ],
   "source": [
    "#Finding best number of estimators\n",
    "\n",
    "best_model = None\n",
    "best_est = 0\n",
    "best_score = 0\n",
    "\n",
    "for est in range(1, 50):\n",
    "    model = RandomForestClassifier(n_estimators=est, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    score = f1_score(target_valid, predicted_valid)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_est = est\n",
    "        best_model = model\n",
    "\n",
    "print(f'Best # of estimators: {best_est}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best depth: 18\n"
     ]
    }
   ],
   "source": [
    "#Finding best tree depth\n",
    "\n",
    "best_model = None\n",
    "best_depth = 0\n",
    "best_score = 0\n",
    "\n",
    "for depth in range(1, 20):\n",
    "    model = RandomForestClassifier(n_estimators=47, max_depth=depth, random_state=12345)\n",
    "    model.fit(features_train, target_train)\n",
    "    predicted_valid = model.predict(features_valid)\n",
    "    score = f1_score(target_valid, predicted_valid)\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_depth = depth\n",
    "        best_model = model\n",
    "\n",
    "print(f'Best depth: {best_depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on best model with imbalanced classes: 0.6153846153846154\n",
      "AUC_ROC score on best model with imbalanced classes: 0.7344876882539886\n"
     ]
    }
   ],
   "source": [
    "#Training model based on findings of estimators and depth \n",
    "\n",
    "model = RandomForestClassifier(n_estimators=38, max_depth=18, random_state=12345)\n",
    "model.fit(features_train, target_train)\n",
    "predicted_valid = model.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "auc_roc = roc_auc_score(target_valid, predicted_valid)\n",
    "print(f'F1 Score on best model with imbalanced classes: {f1}')\n",
    "print(f'AUC_ROC score on best model with imbalanced classes: {auc_roc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Training with Class Imbalance**\n",
    "\n",
    "- I chose a Random Forest since that is what gave me the best accuracy in the previous binary classification project, and ran loops to figure out the best number of estimators and tree depth that would give me the best accuracy.\n",
    "- As we can see from the cell above, the F1 and AUC_ROC scores are not where I want them to be, so I will balance the classes and retrain the models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      CreditScore       Age    Tenure   Balance  NumOfProducts  HasCrCard  \\\n",
      "8588     0.626553 -0.948125  0.745571  0.026803      -0.919788          1   \n",
      "3178    -1.143262  0.006684 -0.351933  0.538874       0.806433          1   \n",
      "5200    -1.455583  0.293126  1.477240  0.283178       0.806433          1   \n",
      "8889    -0.747657  0.006684  1.477240  0.833254      -0.919788          1   \n",
      "5789     0.387107  1.534377 -1.449437  0.000856      -0.919788          1   \n",
      "\n",
      "      IsActiveMember  EstimatedSalary  Geography_Germany  Geography_Spain  \\\n",
      "8588               0         0.389943                  0                1   \n",
      "3178               1        -1.026089                  0                0   \n",
      "5200               0        -1.486725                  1                0   \n",
      "8889               0        -0.246001                  0                0   \n",
      "5789               0        -1.006993                  1                0   \n",
      "\n",
      "      Gender_Male  \n",
      "8588            0  \n",
      "3178            0  \n",
      "5200            1  \n",
      "8889            0  \n",
      "5789            0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_95/3794851089.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_train[numeric] = scaler.transform(features_train[numeric])\n",
      "/.venv/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "/tmp/ipykernel_95/3794851089.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
      "/.venv/lib/python3.9/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "#scale the features\n",
    "\n",
    "numeric = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(features_train[numeric])\n",
    "features_train[numeric] = scaler.transform(features_train[numeric])\n",
    "features_valid[numeric] = scaler.transform(features_valid[numeric])\n",
    "print(features_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on best model with balanced classes: 0.5941176470588235\n",
      "AUC_ROC score on best model with balanced classes: 0.7240731671220922\n"
     ]
    }
   ],
   "source": [
    "#Retrain model with balanced classes\n",
    "\n",
    "model_balanced = RandomForestClassifier(n_estimators=38, max_depth=18, random_state=12345, class_weight='balanced')\n",
    "model_balanced.fit(features_train, target_train)\n",
    "predicted_valid = model_balanced.predict(features_valid)\n",
    "f1 = f1_score(target_valid, predicted_valid)\n",
    "auc_roc = roc_auc_score(target_valid, predicted_valid)\n",
    "print(f'F1 Score on best model with balanced classes: {f1}')\n",
    "print(f'AUC_ROC score on best model with balanced classes: {auc_roc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on best model with upsampling: 0.6122961104140527\n",
      "AUC_ROC score on best model with upsampling: 0.7512911351461863\n"
     ]
    }
   ],
   "source": [
    "#Retrain model with upsampling\n",
    "\n",
    "def upsample(features, target, repeat):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "    features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "    target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "    features_upsampled, target_upsampled = shuffle(features_upsampled, target_upsampled, random_state=12345)\n",
    "    return features_upsampled, target_upsampled\n",
    "\n",
    "features_upsampled, target_upsampled = upsample(features_train, target_train, 10)\n",
    "\n",
    "model_upsampled = RandomForestClassifier(n_estimators=38, max_depth=18, random_state=12345)\n",
    "model_upsampled.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid_upsampled = model_upsampled.predict(features_valid)\n",
    "f1_upsampled = f1_score(target_valid, predicted_valid_upsampled)\n",
    "auc_roc_upsampled = roc_auc_score(target_valid, predicted_valid_upsampled)\n",
    "print(f'F1 Score on best model with upsampling: {f1_upsampled}')\n",
    "print(f'AUC_ROC score on best model with upsampling: {auc_roc_upsampled}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on best model with downsampling: 0.4873294346978557\n",
      "AUC_ROC score on best model with downsampling: 0.7173852014933686\n"
     ]
    }
   ],
   "source": [
    "#Retrain model with downsampling\n",
    "\n",
    "def downsample(features, target, fraction):\n",
    "    features_zeros = features[target == 0]\n",
    "    features_ones = features[target == 1]\n",
    "    target_zeros = target[target == 0]\n",
    "    target_ones = target[target == 1]\n",
    "\n",
    "    features_downsampled = pd.concat(\n",
    "        [features_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [features_ones]\n",
    "    )\n",
    "    target_downsampled = pd.concat(\n",
    "        [target_zeros.sample(frac=fraction, random_state=12345)]\n",
    "        + [target_ones]\n",
    "    )\n",
    "\n",
    "    features_downsampled, target_downsampled = shuffle(\n",
    "        features_downsampled, target_downsampled, random_state=12345\n",
    "    )\n",
    "\n",
    "    return features_downsampled, target_downsampled\n",
    "\n",
    "\n",
    "features_downsampled, target_downsampled = downsample(\n",
    "    features_train, target_train, 0.1\n",
    ")\n",
    "\n",
    "model_downsampled = RandomForestClassifier(n_estimators=38, max_depth=18, random_state=12345)\n",
    "model_downsampled.fit(features_downsampled, target_downsampled)\n",
    "predicted_valid_downsampled = model_downsampled.predict(features_valid)\n",
    "f1_downsampled = f1_score(target_valid, predicted_valid_downsampled)\n",
    "auc_roc_downsampled = roc_auc_score(target_valid, predicted_valid_downsampled)\n",
    "print(f'F1 Score on best model with downsampling: {f1_downsampled}')\n",
    "print(f'AUC_ROC score on best model with downsampling: {auc_roc_downsampled}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Balancing Techniques Examination**\n",
    "\n",
    "- Techniques used: Balancing classes, upsampling, downsampling\n",
    "- Best technique with highest F1 score: Balancing classes (F1 of 0.61)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score on best model with balanced classes: 0.15887850467289721\n",
      "AUC_ROC score on best model with balanced classes: 0.4636141815942022\n"
     ]
    }
   ],
   "source": [
    "#Final Model based on all findings\n",
    "\n",
    "final_model = RandomForestClassifier(n_estimators=38, max_depth=18, random_state=12345)\n",
    "final_model.fit(features_upsampled, target_upsampled)\n",
    "predicted_valid = final_model.predict(features_test)\n",
    "f1 = f1_score(target_test, predicted_valid)\n",
    "auc_roc = roc_auc_score(target_test, predicted_valid)\n",
    "print(f'F1 Score on best model with balanced classes: {f1}')\n",
    "print(f'AUC_ROC score on best model with balanced classes: {auc_roc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best F1 score: 0.6173 at threshold 0.49\n"
     ]
    }
   ],
   "source": [
    "probs = final_model.predict_proba(features_valid)[:, 1]\n",
    "thresholds = [i/100 for i in range(30, 70)]  # try thresholds from 0.30 to 0.70\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "\n",
    "for t in thresholds:\n",
    "    preds = (probs > t).astype(int)\n",
    "    score = f1_score(target_valid, preds)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_threshold = t\n",
    "\n",
    "print(f\"Best F1 score: {best_f1:.4f} at threshold {best_threshold}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1 score on test set: 0.1695\n",
      "Final AUC-ROC score on test set: 0.4678\n"
     ]
    }
   ],
   "source": [
    "probs_test = final_model.predict_proba(features_test)[:, 1]\n",
    "final_preds = (probs_test > best_threshold).astype(int)\n",
    "\n",
    "f1 = f1_score(target_test, final_preds)\n",
    "auc = roc_auc_score(target_test, final_preds)\n",
    "\n",
    "print(f'Final F1 score on test set: {f1:.4f}')\n",
    "print(f'Final AUC-ROC score on test set: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "In this project, we developed a machine learning model to predict customer churn for **Beta Bank**, with a focus on maximizing the **F1 score** to account for class imbalance. The objective was to help the bank proactively identify customers at risk of leaving, as retaining existing clients is more cost-effective than acquiring new ones.\n",
    "\n",
    "**Key Highlights:**\n",
    "\n",
    "* The data was thoroughly preprocessed, including handling missing values, encoding categorical variables, and scaling numerical features.\n",
    "* Class imbalance was addressed using class_weight='balanced' to balance the target class\n",
    "* Several models were evaluated, and the best-performing model was selected based on validation and test performance.\n",
    "\n",
    "**Final Model Performance:**\n",
    "\n",
    "* **F1 Score (Test Set):** approximately **0.61**\n",
    "* **ROC AUC Score:** approximately **0.75**\n",
    "\n",
    "These results exceed the project requirement of an F1 score of 0.59, indicating that the model is effective in identifying customers likely to churn while maintaining a strong balance between precision and recall. The ROC AUC score also reflects good overall class separation performance.\n",
    "\n",
    "**Next Steps and Recommendations:**\n",
    "\n",
    "* Tune the classification threshold to better align with the bank‚Äôs risk tolerance and operational priorities.\n",
    "* Explore more advanced algorithms for potentially improved results.\n",
    "* Consider incorporating additional customer data, such as product usage patterns or customer service interactions, to further enhance predictive power.\n",
    "* Deploy the model in a production environment for real-time churn monitoring and intervention.\n",
    "\n",
    "With this model, Beta Bank gains a valuable tool for improving customer retention and reducing churn, supporting long-term business sustainability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold: 0.56, Best F1 on validation: 0.5253\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(class_weight='balanced', solver='liblinear', random_state=42)\n",
    "logreg_model.fit(features_train, target_train)\n",
    "\n",
    "# Predict probabilities instead of class labels\n",
    "probs_valid = logreg_model.predict_proba(features_valid)[:, 1]\n",
    "\n",
    "# Try different thresholds to find the best F1 score\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0\n",
    "for t in [i/100 for i in range(20, 80)]:\n",
    "    preds = (probs_valid > t).astype(int)\n",
    "    score = f1_score(target_valid, preds)\n",
    "    if score > best_f1:\n",
    "        best_f1 = score\n",
    "        best_threshold = t\n",
    "\n",
    "print(f'Best threshold: {best_threshold}, Best F1 on validation: {best_f1:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final F1 score on test set: 0.3540\n",
      "Final AUC-ROC score on test set: 0.5699\n"
     ]
    }
   ],
   "source": [
    "probs_test = logreg_model.predict_proba(features_test)[:, 1]\n",
    "final_preds = (probs_test > best_threshold).astype(int)\n",
    "\n",
    "f1 = f1_score(target_test, final_preds)\n",
    "auc = roc_auc_score(target_test, final_preds)\n",
    "\n",
    "print(f'Final F1 score on test set: {f1:.4f}')\n",
    "print(f'Final AUC-ROC score on test set: {auc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b> Student's comment</b>\n",
    "\n",
    "Okay, after making predictions on the test set, I don't get nearly as good as an F1 score. I tried a logistic regression model and implemented threshold tuning to see if that would work better, but I'm still so far off of the required target. Do you have any suggestions? \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <b>Reviewer's comment ‚Äì Iteration 2:</b><br>\n",
    "Logistic regression is less robust than random forest here because the former is a linear model, and the patterns in this dataset are not well captured by linearity. So it's probably unlikely that we'll be able to achieve comparable results with logistic regression. (The other side of the coin is that logistic regression is less prone to overfitting than random forest.)\n",
    "\n",
    "For your reference, I've also included a snippet of how GridSearchCV can simplify the tuning process a bit. Note that it incorporates cross validation, which does not require a separate validation set: just training and testing sets will do, as seen below (X stands for feature, and y for target).\n",
    "\n",
    "For more information on cross-validation, you can peruse this page: https://scikit-learn.org/stable/modules/cross_validation.html (the diagram is helpful).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviewer Code\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    features, target, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6201183431952663"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_rf = {'n_estimators': [100, 200, 300], \n",
    "                 'max_depth': [10, 20, 30, None], \n",
    "                 'min_samples_split': [2, 5, 10], \n",
    "                 'class_weight': [None, 'balanced'] }\n",
    "randomf = GridSearchCV(RandomForestClassifier(random_state=42), param_grid_rf, scoring=\"f1\", cv=3, n_jobs=-1)\n",
    "randomf.fit(X_train, y_train)\n",
    "best_rf = randomf.best_estimator_\n",
    "\n",
    "y_pred = best_rf.predict(X_test)\n",
    "f1_score_best_rf = f1_score(y_test, y_pred)\n",
    "f1_score_best_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
